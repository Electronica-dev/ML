{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17002377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dda3c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "688338f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(set(''.join(words)))\n",
    "s_to_i = {s:i+1 for i,s in enumerate(chars)}\n",
    "s_to_i['.'] = 0\n",
    "i_to_s = {i:s for s,i in s_to_i.items()}\n",
    "vocab_size = len(i_to_s)\n",
    "print(i_to_s)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7637129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "  X, Y = [], []\n",
    "\n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = s_to_i[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d4738",
   "metadata": {},
   "source": [
    "### MLP revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3857e005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11897\n"
     ]
    }
   ],
   "source": [
    "n_emb = 10 # dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # no. of neurons in the hidden layer\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "# the multiplier is calculated via Kaiming init\n",
    "C = torch.randn(vocab_size, n_emb, \t\t\t\tgenerator=g) * (5/3)/(n_emb * block_size)**0.5\n",
    "W1 = torch.randn(block_size * n_emb, n_hidden, \tgenerator=g) * 0.2\n",
    "b1 = torch.randn(n_hidden,\t\t\t\t\t\tgenerator=g) * 0.01\n",
    "# multiplying by 0.01 in order to have a good initial loss\n",
    "# good initial loss can be calculated because it's the NLL of 1/27 = 3.2958\n",
    "W2 = torch.randn(n_hidden, vocab_size, \t\t\tgenerator=g) * 0.01\n",
    "b2 = torch.randn(vocab_size, \t\t\t\t\tgenerator=g) * 0\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "\tp.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36809327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3031\n",
      "  10000/ 200000: 2.1448\n",
      "  20000/ 200000: 2.3168\n",
      "  30000/ 200000: 2.3945\n",
      "  40000/ 200000: 1.9721\n",
      "  50000/ 200000: 2.4471\n",
      "  60000/ 200000: 2.3960\n",
      "  70000/ 200000: 2.0547\n",
      "  80000/ 200000: 2.3534\n",
      "  90000/ 200000: 2.0976\n",
      " 100000/ 200000: 1.7685\n",
      " 110000/ 200000: 2.1997\n",
      " 120000/ 200000: 1.8678\n",
      " 130000/ 200000: 2.4473\n",
      " 140000/ 200000: 2.2826\n",
      " 150000/ 200000: 2.1977\n",
      " 160000/ 200000: 1.8869\n",
      " 170000/ 200000: 1.7446\n",
      " 180000/ 200000: 1.8655\n",
      " 190000/ 200000: 1.8877\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "\n",
    "\t# minibatch construction\n",
    "\tix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "\tXb, Yb = Xtr[ix], Ytr[ix] # batch X, Y\n",
    "\n",
    "\t# forward pass\n",
    "\temb = C[Xb] # embed characters into vectors\n",
    "\tembcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\thpreact = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\th = torch.tanh(hpreact) # hidden layer\n",
    "\tlogits = h @ W2 + b2 # output layer\n",
    "\tloss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "\t# backward pass\n",
    "\tfor p in parameters:\n",
    "\t\tp.grad = None\n",
    "\tloss.backward()\n",
    "\n",
    "\t# update\n",
    "\tlr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "\tfor p in parameters:\n",
    "\t\tp.data += -lr * p.grad\n",
    "\n",
    "\t# track stats\n",
    "\tif i % 10000 == 0:\n",
    "\t\tprint(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\tlossi.append(loss.log10().item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6994ed",
   "metadata": {},
   "source": [
    "### Kaiming Initialization\n",
    "- Derivative of `tanh` = `1 - tanh**2`\n",
    "- Its always in the range of `[0, 1]`, essentially making it an \"attenuation\" function because of the chain rule: `gradient_to_layer_below = gradient_from_above Ã— local_derivative` (for tanh, it's always less than 1)\n",
    "- If we have a lot of values near to 1/-1, that essentially means that we are \"killing\" the gradient\n",
    "- The plot below shows that we have this issue  \n",
    "<br>![](./images/tanh-preact.png)\n",
    "- We also plot the values of the hidden layer to have a better visual representation of how many values are like this. We see that while most of it is white (which is not good), we do not have _entire_ columns of white which would mean that there is a \"dead\" neuron: that is, that neuron will never train  \n",
    "<br>![](./images/h-values.png)\n",
    "- We mitigate this by reducing the values of the `W1` and `b1` by multiplying them with something like `0.2` and `0.01` respectively and regenerate the graphs. We see that the graphs are much better  \n",
    "<br>![](./images/tanh-preact-2.png)\n",
    "![](./images/h-values-2.png)\n",
    "- We got the values `0.2` and `0.01` by using fairly unscientific methods; we would like to get to these numbers in a more principled manner. We use the concept of Kaiming initialization for that (Paper: [Kaiming et al](https://arxiv.org/abs/1502.01852))\n",
    "- PyTorch has [inbuilt Kaiming initialization](https://docs.pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_normal_), we make use of that documentation to get the value which we multiply with for initializing W1 with a calculated constant instead of just `0.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef81c7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13d1dd970>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "446ceaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 3.2803754806518555\n",
      "val 3.2805075645446777\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e62c654",
   "metadata": {},
   "source": [
    "### BatchNorm: Batch normalization\n",
    "- Paper: https://arxiv.org/pdf/1502.03167\n",
    "- We would like the preactivation weights (`hpreact`), at least at initialization, to be roughly gaussian (std dev = 1) because too extreme values would either destroy the gradiend or make `tanh` act as a pass-through\n",
    "- Batch normalization solves that by just literally taking these weights of the hidden layer and just normalize them\n",
    "- This works because the process of normalization is a bunch of mathematical expressions which are completely differentiable\n",
    "- `hpreact = (hpreact - hpreact.mean(0, keepdim=True)) / (hpreact.std(0, keepdim=True))`\n",
    "- To make the neural network to \"learn\" and manipulate the weights so that the hidden layer's is not forced to be normalized in every step, we multiply it by a certain gain and add a certain bias\n",
    "  \n",
    "  `bngain = torch.ones((1, n_hidden))`\n",
    "  \n",
    "  `bnbias = torch.zeros((1, n_hidden))`\n",
    "  \n",
    "  These will be included in the parameters list so that they can be trained\n",
    "  \n",
    "  <img src=\"./images/batch-norm.png\" alt=\"batch-norm\" width=\"400\"/>\n",
    "\n",
    "  *The \"+ $\\epsilon$\" in the normalization equation is a very small constant (usually 1e-5) added to the denominator so that in cases where the standard deviation is zero, it does not result in a divide by zero error; we have a small MLP, so we will most probably not run into that and are avoiding it\n",
    "\n",
    "**Side effect of batch normalization**\n",
    "- During the forward pass and backward pass, the mean and std is calculated with the values of the _entire_ batch, wherein the values are sampled randomly\n",
    "- So doing the forward pass for a single random sample as well introduces \"noise\"/\"jitter\"/\"padding\" to that tensor\n",
    "- This added, unwanted \"noise\" is actually helpful because it adds certain entropy and acts as a regulizer and mitigates to an extent, the overfitting of the system\n",
    "\n",
    "**Sampling from batch normalization**\n",
    "- Since the mean and std are calculated wrt the entire batch, the neural network expects a batch as an input too, instead of a single example\n",
    "- Solution to this is that once the NN is trained, we calculate the mean and std of the entire batch (`Xtr`) and then use this during inference\n",
    "- People be lazy, so instead of doing this as an additional step, we can just have a running mean and std while training and use them once the training is completed\n",
    "- While calculating the running mean, care has to be taken in considering the `momentum` (a parameter used in the `BatchNorm1d` class in PyTorch), in our case it is `0.001` (from bnmean_running = 0.999 * bnmean_running + `0.001` * bnmeani). For smaller batch sizes, larger momentums can be dangerous because statistically, the mean and the std _may not_ converge to the entire batch's mean and std because it will thrash around quite a bit owing to the smaller batch size\n",
    "\n",
    "**Why `b1` is useless**\n",
    "```python\n",
    "hpreact - mean(hpreact) \n",
    "= (embcat @ W1 + b1) - mean(embcat @ W1 + b1)\n",
    "= (embcat @ W1 + b1) - (mean(embcat @ W1) + b1)\n",
    "= embcat @ W1 - mean(embcat @ W1)\n",
    "```\n",
    "b1 appears in both terms and cancels out. This is because:\n",
    "\n",
    "mean(embcat @ W1 + b1)  \n",
    "= mean(embcat @ W1) + mean(b1)  \n",
    "= mean(embcat @ W1) + b1\n",
    "\n",
    "**The mean of a constant (b1) is just that constant itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f54e0099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "n_emb = 10 # dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # no. of neurons in the hidden layer\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "# the multiplier is calculated via Kaiming init\n",
    "C = torch.randn(vocab_size, n_emb, \t\t\t\tgenerator=g) * (5/3)/(n_emb * block_size)**0.5\n",
    "W1 = torch.randn(block_size * n_emb, n_hidden, \tgenerator=g) * 0.2\n",
    "#b1 = torch.randn(n_hidden,\t\t\t\t\t\tgenerator=g) * 0.01\n",
    "# multiplying by 0.01 in order to have a good initial loss\n",
    "# good initial loss can be calculated because it's the NLL of 1/27 = 3.2958\n",
    "W2 = torch.randn(n_hidden, vocab_size, \t\t\tgenerator=g) * 0.01\n",
    "b2 = torch.randn(vocab_size, \t\t\t\t\tgenerator=g) * 0\n",
    "\n",
    "bngain = torch.ones((1, n_hidden))\n",
    "bnbias = torch.zeros((1, n_hidden))\n",
    "# initalized with zeros because initially, gaussian distribution ensures that the mean is close to zero\n",
    "bnmean_running = torch.zeros((1, n_hidden))\n",
    "# initalized with ones because initially, gaussian distribution ensures that the std is close to one\n",
    "bnstd_running = torch.ones((1, n_hidden))\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "\tp.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d8abab1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m lr = \u001b[32m0.1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i < \u001b[32m100000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.01\u001b[39m \u001b[38;5;66;03m# step learning rate decay\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \tp.data += \u001b[43m-\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# track stats\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m10000\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "\n",
    "\t# minibatch construction\n",
    "\tix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "\tXb, Yb = Xtr[ix], Ytr[ix] # batch X, Y\n",
    "\n",
    "\t# forward pass\n",
    "\temb = C[Xb] # embed characters into vectors\n",
    "\tembcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\thpreact = embcat @ W1 #+ b1 # hidden layer pre-activation\n",
    "\n",
    "\tbnmeani = hpreact.mean(0, keepdim=True)\n",
    "\tbnstdi = hpreact.std(0, keepdim=True)\n",
    "\n",
    "\thpreact = bngain * (hpreact - bnmeani) / bnstdi + bnbias\n",
    "\th = torch.tanh(hpreact) # hidden layer\n",
    "\tlogits = h @ W2 + b2 # output layer\n",
    "\tloss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tbnmean_running = 0.999 * bnmean_running + 0.001 * bnmeani\n",
    "\t\tbnstd_running = 0.999 * bnstd_running + 0.001 * bnstdi\n",
    "\n",
    "\t# backward pass\n",
    "\tfor p in parameters:\n",
    "\t\tp.grad = None\n",
    "\tloss.backward()\n",
    "\n",
    "\t# update\n",
    "\tlr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "\tfor p in parameters:\n",
    "\t\tp.data += -lr * p.grad\n",
    "\n",
    "\t# track stats\n",
    "\tif i % 10000 == 0:\n",
    "\t\tprint(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\tlossi.append(loss.log10().item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea1769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.0614492893218994\n",
      "val 2.106208086013794\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "\tx,y = {\n",
    "\t'train': (Xtr, Ytr),\n",
    "\t'val': (Xdev, Ydev),\n",
    "\t'test': (Xte, Yte),\n",
    "\t}[split]\n",
    "\temb = C[x] # (N, block_size, n_embd)\n",
    "\tembcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "\thpreact = embcat @ W1 + b1\n",
    "\thpreact = bngain * (hpreact - bnmean_running) / bnstd_running + bnbias\n",
    "\th = torch.tanh(hpreact) # (N, n_hidden)\n",
    "\tlogits = h @ W2 + b2 # (N, vocab_size)\n",
    "\tloss = F.cross_entropy(logits, y)\n",
    "\tprint(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df314244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "makemore-YrzdWSWv-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
